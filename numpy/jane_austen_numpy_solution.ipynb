{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jane Austen assignment solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using numpy arrays for frequency data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we build a 2D array representing a textual data set. There are tools that will do what we doing here much faster than the code you write, but the idea is for you to gain a better understanding of what the actual computational representation of the data is by building it yourself.\n",
    "\n",
    "Steps\n",
    "\n",
    "1.  We loop through a set of documents getting the vocab counts for each.  Our final vocabulary is the union of the vocabularies of the documents, i.e., every word we've seen in the data set, even if it occurred in only one document.\n",
    "2. Let D be the number of documents.  Let V be the vocab size.  We build a DxV matrix M representing the frequency counts of each word in each document.  `M[i,j]` is the count of the `j`-th word in the `i`-th document.\n",
    "\n",
    "The matrix M can be passed directly to a machine learning algorithm as its training matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from collections import Counter\n",
    "\n",
    "docset = ['pride_and_prejudice','northanger_abbey',\n",
    "          'emma', 'mansfield_park',\n",
    "          'sense_and_sensibility', 'persuasion']\n",
    "vocab = set()\n",
    "doc_counts = []\n",
    "for d in docset:\n",
    "    with open('austen/{0}.txt'.format(d),'r') as fh:\n",
    "        ctr = Counter(fh.read().lower().split())\n",
    "        vocab.update(ctr.keys())\n",
    "        doc_counts.append(ctr)\n",
    "\n",
    "vocab = sorted(list(vocab))\n",
    "(D,V) = (len(doc_counts), len(vocab))\n",
    "\n",
    "M = np.zeros((D,V))\n",
    "for i in range(D):\n",
    "    doc_ctr_i = doc_counts[i]\n",
    "    for j in range(V):\n",
    "        M[i,j] = doc_ctr_i[vocab[j]]\n",
    "\n",
    "# The words counts for each document.\n",
    "# A vector of length 6. Applying norm\n",
    "# function to rows, M[0,:], M[1,:], M[2,:], etc., \n",
    "# i.e., slices along dimension 1\n",
    "doc_sizes = LA.norm(M,ord=1,axis=1)\n",
    "\n",
    "#def divide (x,y):\n",
    "#    return x/y\n",
    "\n",
    "# Divide every word count in a doc by the doc size of the doc\n",
    "# Divide each column vector [a vector of length 6] elementwise\n",
    "# by doc_sizes [another vector of length 6].\n",
    "# We are applying the function to columns, \n",
    "# M[:,0],M[:,1,],M[:,2], etc., i.e., slices along dimension, 0.\n",
    "M_norm = np.apply_along_axis(np.divide,0,M,doc_sizes)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the `apply_along_axis` function.  The basic idea is to apply any function of a 1D array, to either rows or columns of a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10],\n",
       "       [11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def my_average(a):\n",
    "    \"\"\"Find size of average element of a 1-D array\"\"\"\n",
    "    return sum(a)/float(len(a))\n",
    "\n",
    "# a 3x3 array.\n",
    "#X = np.array([[1,2,3,4,5], [4,5,6,7,8], [7,8,9,10,11]])\n",
    "X = np.array([[1,2,3,4,5], [6,7,8,9,10], [11,12,13,14,15]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axis 0, apply my_average to 5 cols of X [  6.   7.   8.   9.  10.]\n",
      "Axis 1, apply my_average to to 3 rows of X [  3.   8.  13.]\n"
     ]
    }
   ],
   "source": [
    "print 'Axis 0, apply my_average to 5 cols of X',np.apply_along_axis(my_average, 0, X)\n",
    "print 'Axis 1, apply my_average to to 3 rows of X',np.apply_along_axis(my_average, 1, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computing `M_norm` above, we gave `apply_along_axis` one more argument `doc_sizes` which is interpreted as an additional argument of `np.divide`, so this means we divide every column elementwise by the document sizes vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `M` gives the counts for a word in a document, and `M_norm` the proportion of the document the word occupies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 39548) (6, 39548)\n",
      "1 northanger_abbey\n",
      "0 pride_and_prejudice\n",
      "34915 the\n",
      "3321.0 0.0414327419717\n",
      "4479.0 0.0359504928243\n"
     ]
    }
   ],
   "source": [
    "print M.shape, M_norm.shape\n",
    "print docset.index('northanger_abbey'), docset[1]\n",
    "print docset.index('pride_and_prejudice'),docset[0]\n",
    "print vocab.index('the'),vocab[34915]\n",
    "\n",
    "print M[1,34915], M_norm[1,34915]\n",
    "print M[0,34915], M_norm[0,34915]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the code above carefully, make sure you understand it. Answer the following questions about `M` and `M_norm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  What is the size of Jane Austen's vocabulary?  How many words long is the Jane Austen canon (the sum of the lengths [in words] of the 6 novels)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vocab size 39548\n",
      "Size of canon 735640.0\n"
     ]
    }
   ],
   "source": [
    "print 'Vocab size', len(vocab)\n",
    "print 'Size of canon', sum(doc_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 124588.,   80154.,  160449.,  162553.,  121590.,   86306.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, she has not passed the million word milestone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)  How many times does \"time\" occur in *Pride and Prejudice*?  Show the computations you use to compute this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35427\n",
      "0\n",
      "Count of \"time\" in \"Pride and Prejudice\": 136.0\n"
     ]
    }
   ],
   "source": [
    "time_index = vocab.index('time')\n",
    "pride_and_prejudice_index = docset.index('pride_and_prejudice')\n",
    "print time_index\n",
    "print pride_and_prejudice_index \n",
    "print 'Count of \"time\" in \"Pride and Prejudice\":',M[pride_and_prejudice_index,time_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)  How many times does \"year\" occur in *Sense and Sensibility*?  Show your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39291\n",
      "4\n",
      "Count of \"year\" in \"Sense and Sensibility\": 14.0\n"
     ]
    }
   ],
   "source": [
    "year_index = vocab.index('year')\n",
    "sense_and_sensibility_index = docset.index('sense_and_sensibility')\n",
    "print year_index\n",
    "print sense_and_sensibility_index\n",
    "print 'Count of \"year\" in \"Sense and Sensibility\":',M[sense_and_sensibility_index,year_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)  Note that 'It' is not present in the vocabulary.  Can we conclude that Jane Austen never starts a sentence with 'It'?  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire string of each novel is lower cased before being passed to the counter for that novel:\n",
    "\n",
    "```\n",
    "ctr = Counter(fh.read().lower().split())\n",
    "```\n",
    "\n",
    "So we only know that the word `it` occurred, not whether it was lower or upper case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5)  Compute an array which gives the counts for the word \"gentleman\" in all 6 Jane Austen novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 18.,  20.,  14.,  10.,  18.,  12.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gentleman_index = vocab.index('gentleman')\n",
    "M[:,gentleman_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that one novel has 20 occurrences of `gentleman` in the count vector above.  That is the novel with index 1. To see which one that is, we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'northanger_abbey'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In two lines of code this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'northanger_abbey'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gentleman_counts = list(M[:,gentleman_index])\n",
    "docset[gentleman_counts.index(max(gentleman_counts))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another equivalent solution (read up on `where` in the `numpy` docs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'northanger_abbey'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gentleman_counts = M[:,gentleman_index]\n",
    "# `where` returns a tuple of indices\n",
    "max_doc_index = np.where(gentleman_counts==gentleman_counts.max())[0][0]\n",
    "docset[max_doc_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6)  Which novel has the largest number of tokens of \"truth\"?  Show your computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emma'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_index = vocab.index('truth')\n",
    "truth_counts = list(M[:,truth_index])\n",
    "docset[truth_counts.index(max(truth_counts))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7)  Which novel has the largest proportion of occurrences of \"lady\" and which the largest proportion of occurrences of \"gentleman\"?  Which word shows up more often in Austen's writings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greatest proportion of tokens of \"lady\": persuasion\n"
     ]
    }
   ],
   "source": [
    "lady_index = vocab.index('lady')\n",
    "lady_props = list(M_norm[:,lady_index])\n",
    "print 'Greatest proportion of tokens of \"lady\":', docset[lady_props.index(max(lady_props))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greatest proportion of tokens of \"gentleman\": northanger_abbey\n"
     ]
    }
   ],
   "source": [
    "gentleman_index = vocab.index('gentleman')\n",
    "gentleman_counts = list(M_norm[:,gentleman_index])\n",
    "print 'Greatest proportion of tokens of \"gentleman\":', docset[gentleman_counts.index(max(gentleman_counts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total counts  \"lady\" 716.0\n",
      "Total counts  \"gentleman\" 92.0\n"
     ]
    }
   ],
   "source": [
    "lady_index = vocab.index('lady')\n",
    "gentleman_index = vocab.index('gentleman')\n",
    "total_lady_counts = sum(M[:,lady_index])\n",
    "total_gentleman_counts = sum(M[:,gentleman_index])\n",
    "print 'Total counts  \"lady\"', total_lady_counts\n",
    "print 'Total counts  \"gentleman\"', total_gentleman_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: It's not even close.  Jane Austen writes about the world of women.  \n",
    "\n",
    "An interesting fact reported to me by a student of Austen: There are no scenes in which a woman is not present in the entire Austen canon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 166.   27.   32.  169.  122.  200.]\n",
      "[ 18.  20.  14.  10.  18.  12.]\n"
     ]
    }
   ],
   "source": [
    "print M[:,lady_index]\n",
    "print M[:,gentleman_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Northanger Abbey* and *Emma* are the outliers for *lady*.\n",
    "\n",
    "Temporal order:\n",
    "\n",
    "1. Sense and Sensibility\n",
    "2. Pride and Prejudice\n",
    "3. Northanger Abbey\n",
    "4. Mansfield Park\n",
    "5. Emma\n",
    "6. Persuasion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
