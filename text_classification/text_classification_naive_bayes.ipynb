{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about text classification using Naive Bayes.  Section 2 tells you about the data\n",
    "and NLTK.  Section 3 tells you about training a Naive Bayes classifier and how\n",
    "you can modify the classifier's behavior.  Section 4 tells you what you have\n",
    "to hand in to get credit for this portion of the final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data and NLTK Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook you need to have some NLTK `movie reviews` data installed.  First make sure you have nltk installed as a Python module (or the first line in the code block below won't work).  Then install the data as follows:\n",
    "\n",
    "```\n",
    "import nltk\n",
    "nltk.download()\n",
    "```\n",
    "\n",
    "This pops up a separate window.  It has several tabs, one of them labeled `corpora`.  Select that tab and you will see a long alphabetically ordered list of all the corpora `NLTK` supplies.  Scroll down and select `Movie Reviews` and click on `Download`.  This will install that data on your machine, and all the code in this notebook\n",
    "should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peliminaries:  Code for getting data and extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_features (words):\n",
    "    \"\"\" \n",
    "    This is the simplest possible feature representation of a document.\n",
    "    \n",
    "    Each word is a feature.  We return a dictionary that represents the\n",
    "    set of vocabulary words in the document.\n",
    "    \n",
    "    You can improve the performance of your classifier by being more selective\n",
    "    about what features you use.\n",
    "    \"\"\"\n",
    "    return dict((word, True) for word in words)\n",
    "\n",
    "\n",
    "def extract_features (corpus, file_ids, cls, feature_extractor=unigram_features):\n",
    "    \"\"\"\n",
    "    Turn a set of files all belonging to one class into a list\n",
    "    of (feature dictionary, cls) pairs, to be used in testing or training\n",
    "    a classifier.\n",
    "    \n",
    "    Whatever you replace extract_features with must continue to return \n",
    "    a list of feature-dictionary cls pairs.  The features in the feature dictionary\n",
    "    can change, but the second member of the pair must always be the class (`cls` in the\n",
    "    code below).\n",
    "    \"\"\"\n",
    "    return [(feature_extractor(corpus.words(i)), cls) \n",
    "            for i in file_ids]\n",
    "\n",
    "\n",
    "def get_words_from_corpus (corpus, file_ids):\n",
    "\n",
    "    for file_id in file_id|s:\n",
    "        words = corpus.words(file_id)\n",
    "        for word in words:\n",
    "            yield word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest approach to th problem below is to replace  `unigram` features.  Try that first. \n",
    "\n",
    "You need to write another function that is more selective about what words will be used\n",
    "as features.  A simple replacement function might be called `restricted_unigram_features` and \n",
    "defined as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restricted_unigram_features (words):\n",
    "    return dict((word, True) for word in words if word in my_preferred_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would then replace the call to `unigram_features` with a call to `restricted_unigram_features` in the \n",
    "code below.  You would of course also have to define the list `my_preferred_words`.  In order to\n",
    "that you might want to pay attention to what `most_informative_features` tells you about your baseline\n",
    "system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In line 3  of the next cell, we import the NLTK Bo Pang and Lillian Lee's movie reviews corpus.  Line 5 prints some information about the corpus properties; these appear in the output cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a corpus of movie review data\n",
    "# 2000 positive and negative reviews, evenly balanced.\n",
    "from nltk.corpus import movie_reviews as mr\n",
    "\n",
    "# If you want to read the corpus collectors' introduction to\n",
    "# this corpus, uncomment the next line.\n",
    "#print mr.readme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie review data is packaged up as an NLTK corpus, which \n",
    "gives us access to a number of tools for text handling.  The simplest\n",
    "is that we have two views of the movie review data, word by word and character by character.\n",
    "\n",
    "The character by character view uses the `raw` method, which returns all the data with no argument, or just the data from a single file with a file-id argument.  In the example below we return the first 100 characters from the first positive movie review.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "films adapted from comic books have had plenty of success , whether they're about superheroes ( batm\n"
     ]
    }
   ],
   "source": [
    "data = dict(pos = mr.fileids('pos'),\n",
    "            neg = mr.fileids('neg'))\n",
    "print(mr.raw(data['pos'][0])[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word by word character view uses the `words` method::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['films', 'adapted', 'from', 'comic', 'books', 'have', 'had', 'plenty', 'of', 'success', ',']\n"
     ]
    }
   ],
   "source": [
    "print(mr.words(data['pos'][0])[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the word by word view when we extract features (`mr.words` in the definition of `extract_features`).\n",
    "\n",
    "You can experiment with using other views as well.  That would mean redefining\n",
    "`extract_features`.  For example, it may pay to pay more attention to the first and last\n",
    "paragraphs of a movie review when classifying it.  Then you would want the\n",
    "`mr.paras` view.  You would have to replace `unigram_features` with another function\n",
    "that expected a sequence of paragraphs instead of a sequence of words.\n",
    "\n",
    "The key point is that whatever you replace `extract_features` with must return \n",
    "the kind of thing `extract_features` returns now, a list of dictionary,class pairs,\n",
    "one for each movie review file.  The class is always `pos` or `neg` (this was a positive or negative\n",
    "review).  The feature dictionary contains a set of Boolean features, whose values\n",
    "are `True` or `False` (those are special Python constants and case must be preserved).\n",
    "So for example, the ungram feature representation of a document containing just one sentence,\n",
    "`See me walk` is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unigram_features() missing 1 required positional argument: 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-14d0757e9335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munigram_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unigram_features() missing 1 required positional argument: 'words'"
     ]
    }
   ],
   "source": [
    "unigram_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'walk': True, 'see': True, 'me': True}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dict = {'walk':True, 'see':True, 'me':True}\n",
    "feat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use bigram features too it would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feat_dict = feat_dict = {'walk':True, 'see':True, 'me':True,('me','walk'):True, ('see','me'):True, ('me','walk'):True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline System: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below defines and trains the baseline system you will use for this exercise.  It uses\n",
    "the unigram feature extractor defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as mr\n",
    "\n",
    "data = dict(pos = mr.fileids('pos'),\n",
    "            neg = mr.fileids('neg'))\n",
    "\n",
    "#######################################################################\n",
    "#\n",
    "#  Dividing up the data\n",
    "#######################################################################\n",
    "\n",
    "# 1000 reviews. Use 90% of the data for training.  Use 10% for test.\n",
    "test_start_index = 900\n",
    "\n",
    "neg_training = extract_features(mr, data['neg'][:test_start_index], 'neg',\n",
    "                                feature_extractor=unigram_features)\n",
    "\n",
    "# Use 10% for testing the classifier on unseen data.\n",
    "neg_test = extract_features(mr, data['neg'][test_start_index:], 'neg',\n",
    "                                feature_extractor=unigram_features)\n",
    "\n",
    "pos_training = extract_features(mr, data['pos'][:test_start_index],'pos',\n",
    "                                feature_extractor=unigram_features)\n",
    "\n",
    "pos_test = extract_features(mr, data['pos'][test_start_index:],'pos',\n",
    "                                feature_extractor=unigram_features)\n",
    "\n",
    "train_set = pos_training + neg_training\n",
    "\n",
    "test_set = pos_test + neg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 2 imports the movie review data from NLTK, and lines 4 and 5 store the two halves of the corpus in a dictionary (positive and negative reviews, 1000 of each).   The commands on \n",
    "the next few lines extract features from the data files, sorting them in pos and negative training and positive and negative test sets.  The training set is 90% of the the data; the test set is 10% of the data.  The feature extractor used is `unigram_features`, the simple feature extractor defined in the first code cell of this notebook.  This feature extractor just uses every word that appears in a document as a feature.  \n",
    "\n",
    "Finally in line 31 the positive and negative training data is combined into a single training set, and in line 36, a Naive Bayes (NB) classifier is trained. The code above works as is and defines what you may\n",
    "view as your baseline classifier.\n",
    "\n",
    "When you want to improve your classifier, your easiest strategy is just to change only one thing\n",
    "in the cell above: Change the feature extractor to be something other than `unigram features`.  You\n",
    "would create a new function just like `unigram_features` except that it is more selective about\n",
    "what it's features are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now split the data into two unequal haves, each with positive and negative examples, and called the larger half `train_set` and the smaller half `test_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 900)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['neg']),len(neg_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we **train** the classifier by giving it the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a Naive Bayes Classifier\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "#  Train a classifier on our training data.\n",
    "classifier = NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic feature representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we look at an example representation of a movie review, as it is done\n",
    "in `unigram_features`. It is basically just a set, telling us what words occurred in the review, but not how many times they occurred.  In terms of a Python data structure, it's a dictionary whose keys are the words in the document, and whose values are all `True.`  We're not bothering to represent the words\n",
    "that don't occur in the document, so there are no keys whose value are is `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'in': True,\n",
       "  '1912': True,\n",
       "  ',': True,\n",
       "  'a': True,\n",
       "  'ship': True,\n",
       "  'set': True,\n",
       "  'sail': True,\n",
       "  'on': True,\n",
       "  'her': True,\n",
       "  'maiden': True,\n",
       "  'voyage': True,\n",
       "  'across': True,\n",
       "  'the': True,\n",
       "  'atlantic': True,\n",
       "  'for': True,\n",
       "  'america': True,\n",
       "  '.': True,\n",
       "  'this': True,\n",
       "  'was': True,\n",
       "  'built': True,\n",
       "  'to': True,\n",
       "  'be': True,\n",
       "  'largest': True,\n",
       "  'world': True,\n",
       "  'and': True,\n",
       "  'she': True,\n",
       "  'also': True,\n",
       "  'build': True,\n",
       "  'one': True,\n",
       "  'of': True,\n",
       "  'most': True,\n",
       "  'luxurious': True,\n",
       "  'that': True,\n",
       "  'finally': True,\n",
       "  'unsinkable': True,\n",
       "  'unfortunately': True,\n",
       "  'not': True,\n",
       "  'get': True,\n",
       "  'ticket': True,\n",
       "  'you': True,\n",
       "  'either': True,\n",
       "  ':': True,\n",
       "  'spent': True,\n",
       "  'life': True,\n",
       "  \"'\": True,\n",
       "  's': True,\n",
       "  'savings': True,\n",
       "  'start': True,\n",
       "  'anew': True,\n",
       "  'were': True,\n",
       "  'part': True,\n",
       "  'upper': True,\n",
       "  'class': True,\n",
       "  'had': True,\n",
       "  'money': True,\n",
       "  'spare': True,\n",
       "  'or': True,\n",
       "  'lucky': True,\n",
       "  'enough': True,\n",
       "  'have': True,\n",
       "  'full': True,\n",
       "  'house': True,\n",
       "  'poker': True,\n",
       "  'match': True,\n",
       "  'by': True,\n",
       "  'docks': True,\n",
       "  'like': True,\n",
       "  'jack': True,\n",
       "  'dawson': True,\n",
       "  'makes': True,\n",
       "  'trip': True,\n",
       "  'happens': True,\n",
       "  'at': True,\n",
       "  'right': True,\n",
       "  'place': True,\n",
       "  'time': True,\n",
       "  'rose': True,\n",
       "  'dewitt': True,\n",
       "  'bukater': True,\n",
       "  'first': True,\n",
       "  'passenger': True,\n",
       "  'climbs': True,\n",
       "  'railings': True,\n",
       "  'aft': True,\n",
       "  'with': True,\n",
       "  'thoughts': True,\n",
       "  'jumping': True,\n",
       "  'thus': True,\n",
       "  'is': True,\n",
       "  'started': True,\n",
       "  'tale': True,\n",
       "  'romance': True,\n",
       "  'intrigue': True,\n",
       "  'death': True,\n",
       "  'tragedy': True,\n",
       "  'movie': True,\n",
       "  'about': True,\n",
       "  'tragic': True,\n",
       "  'event': True,\n",
       "  'took': True,\n",
       "  'great': True,\n",
       "  'many': True,\n",
       "  'years': True,\n",
       "  'ago': True,\n",
       "  'an': True,\n",
       "  'even': True,\n",
       "  'should': True,\n",
       "  'taken': True,\n",
       "  'lightly': True,\n",
       "  'as': True,\n",
       "  'any': True,\n",
       "  'other': True,\n",
       "  'bit': True,\n",
       "  'historical': True,\n",
       "  'trivia': True,\n",
       "  'titanic': True,\n",
       "  'shows': True,\n",
       "  'what': True,\n",
       "  'happened': True,\n",
       "  'maybe': True,\n",
       "  '100': True,\n",
       "  '%': True,\n",
       "  'degree': True,\n",
       "  'accuracy': True,\n",
       "  'but': True,\n",
       "  'it': True,\n",
       "  'still': True,\n",
       "  'very': True,\n",
       "  'realisticaly': True,\n",
       "  'now': True,\n",
       "  'both': True,\n",
       "  'story': True,\n",
       "  'its': True,\n",
       "  'own': True,\n",
       "  'backdrop': True,\n",
       "  'serves': True,\n",
       "  'admirably': True,\n",
       "  'brining': True,\n",
       "  'forth': True,\n",
       "  'interesting': True,\n",
       "  'although': True,\n",
       "  'simple': True,\n",
       "  'premise': True,\n",
       "  'captivating': True,\n",
       "  'emotional': True,\n",
       "  'simply': True,\n",
       "  'because': True,\n",
       "  'alone': True,\n",
       "  'brought': True,\n",
       "  'out': True,\n",
       "  'certain': True,\n",
       "  'style': True,\n",
       "  'so': True,\n",
       "  'much': True,\n",
       "  'more': True,\n",
       "  'effective': True,\n",
       "  'movies': True,\n",
       "  'such': True,\n",
       "  'will': True,\n",
       "  'forgotten': True,\n",
       "  'all': True,\n",
       "  'too': True,\n",
       "  'quickly': True,\n",
       "  'then': True,\n",
       "  'are': True,\n",
       "  'something': True,\n",
       "  'produced': True,\n",
       "  'hollywood': True,\n",
       "  'frequency': True,\n",
       "  'attention': True,\n",
       "  'detail': True,\n",
       "  'paid': True,\n",
       "  'remarkable': True,\n",
       "  'whole': True,\n",
       "  'telling': True,\n",
       "  'showing': True,\n",
       "  'brand': True,\n",
       "  'new': True,\n",
       "  'footage': True,\n",
       "  'from': True,\n",
       "  'wreck': True,\n",
       "  'adding': True,\n",
       "  'flavor': True,\n",
       "  'already': True,\n",
       "  'good': True,\n",
       "  'magical': True,\n",
       "  'chemistry': True,\n",
       "  'behind': True,\n",
       "  'acting': True,\n",
       "  'extremely': True,\n",
       "  'cast': True,\n",
       "  'performances': True,\n",
       "  'put': True,\n",
       "  'main': True,\n",
       "  'stars': True,\n",
       "  'admired': True,\n",
       "  'characters': True,\n",
       "  'played': True,\n",
       "  'memorably': True,\n",
       "  'leonardo': True,\n",
       "  'dicaprip': True,\n",
       "  'kate': True,\n",
       "  'winslet': True,\n",
       "  'receive': True,\n",
       "  'least': True,\n",
       "  'nominations': True,\n",
       "  'their': True,\n",
       "  'roles': True,\n",
       "  'looking': True,\n",
       "  'done': True,\n",
       "  'seems': True,\n",
       "  'if': True,\n",
       "  'they': True,\n",
       "  'aren': True,\n",
       "  't': True,\n",
       "  'actually': True,\n",
       "  'casting': True,\n",
       "  'could': True,\n",
       "  'really': True,\n",
       "  'been': True,\n",
       "  'better': True,\n",
       "  'my': True,\n",
       "  'humble': True,\n",
       "  'opinion': True,\n",
       "  'character': True,\n",
       "  'likely': True,\n",
       "  'mentioned': True,\n",
       "  'review': True,\n",
       "  'commentary': True,\n",
       "  'film': True,\n",
       "  'itself': True,\n",
       "  'yes': True,\n",
       "  'read': True,\n",
       "  'correctly': True,\n",
       "  'how': True,\n",
       "  '?': True,\n",
       "  'ask': True,\n",
       "  'well': True,\n",
       "  'sailors': True,\n",
       "  'boats': True,\n",
       "  'men': True,\n",
       "  'tell': True,\n",
       "  'everything': True,\n",
       "  'specifications': True,\n",
       "  'luxuries': True,\n",
       "  'no': True,\n",
       "  'stranger': True,\n",
       "  'mr': True,\n",
       "  'cameron': True,\n",
       "  'brings': True,\n",
       "  'almost': True,\n",
       "  'literal': True,\n",
       "  'sense': True,\n",
       "  'adds': True,\n",
       "  'way': True,\n",
       "  'productions': True,\n",
       "  'cant': True,\n",
       "  'seem': True,\n",
       "  'grasp': True,\n",
       "  'produce': True,\n",
       "  'effect': True,\n",
       "  'i': True,\n",
       "  'above': True,\n",
       "  'sink': True,\n",
       "  'feats': True,\n",
       "  'accomplished': True,\n",
       "  'special': True,\n",
       "  'effects': True,\n",
       "  'wizards': True,\n",
       "  'range': True,\n",
       "  'marvelous': True,\n",
       "  'costumes': True,\n",
       "  'beautifully': True,\n",
       "  'rendered': True,\n",
       "  'scenes': True,\n",
       "  'ships': True,\n",
       "  'sinking': True,\n",
       "  'some': True,\n",
       "  'respects': True,\n",
       "  'cannot': True,\n",
       "  'there': True,\n",
       "  'think': True,\n",
       "  'see': True,\n",
       "  'happening': True,\n",
       "  '(': True,\n",
       "  'your': True,\n",
       "  'imagination': True,\n",
       "  ')': True,\n",
       "  'technical': True,\n",
       "  'wizardry': True,\n",
       "  'just': True,\n",
       "  'spectacular': True,\n",
       "  'getting': True,\n",
       "  'unique': True,\n",
       "  'leave': True,\n",
       "  'amazed': True,\n",
       "  'feat': True,\n",
       "  'since': True,\n",
       "  'monsters': True,\n",
       "  'aliens': True,\n",
       "  'humans': True,\n",
       "  'oversized': True,\n",
       "  'amaze': True,\n",
       "  'pull': True,\n",
       "  'emotions': True,\n",
       "  'theater': True,\n",
       "  'went': True,\n",
       "  'few': True,\n",
       "  'people': True,\n",
       "  'leaving': True,\n",
       "  'tears': True,\n",
       "  'eyes': True,\n",
       "  'fact': True,\n",
       "  'occurred': True,\n",
       "  'home': True,\n",
       "  'punch': True,\n",
       "  'wont': True,\n",
       "  'spoil': True,\n",
       "  'ending': True,\n",
       "  'say': True,\n",
       "  'regardless': True,\n",
       "  'beginning': True,\n",
       "  'end': True,\n",
       "  'value': True,\n",
       "  'quite': True,\n",
       "  'high': True,\n",
       "  'honestly': True,\n",
       "  'watched': True,\n",
       "  'sake': True,\n",
       "  'seeing': True,\n",
       "  'method': True,\n",
       "  'totally': True,\n",
       "  'none': True,\n",
       "  'less': True,\n",
       "  'anything': True,\n",
       "  'grandiose': True,\n",
       "  'production': True,\n",
       "  'sheer': True,\n",
       "  'size': True,\n",
       "  'project': True,\n",
       "  'undertaken': True,\n",
       "  'marveled': True,\n",
       "  'smashingly': True,\n",
       "  'successful': True,\n",
       "  'aims': True,\n",
       "  'achieve': True,\n",
       "  'astonishing': True,\n",
       "  'chance': True,\n",
       "  'go': True,\n",
       "  '!': True,\n",
       "  'might': True,\n",
       "  'best': True,\n",
       "  'ranks': True,\n",
       "  'fairly': True,\n",
       "  'highly': True,\n",
       "  'worth': True,\n",
       "  'watching': True,\n",
       "  'during': True,\n",
       "  '3': True,\n",
       "  'hours': True,\n",
       "  '13': True,\n",
       "  'minutes': True,\n",
       "  'bored': True,\n",
       "  'nor': True,\n",
       "  'does': True,\n",
       "  'wane': True},\n",
       " 'pos')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell, we demonstrate what the classifier does on the first reviews in the the positive and negative training set.  The output window shows that both reviews are correctly classified by the NB classifier we just trained.\n",
    "\n",
    "First, we pick a review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "films adapted from comic books have had plenty of success , whether they ' re about superheroes ( batman , superman , spawn ) , or geared toward kids ( casper ) or the arthouse crowd ( ghost world ) , but there ' s never really been a comic book like from hell before . for starters , it was created by alan moore ( and eddie campbell ) , who brought the medium to a whole new level in the mid ' 80s with a 12 - part series called the watchmen .\n",
      "     . . . . . . \n",
      ", but cinematographer peter deming ( don ' t say a word ) ably captures the dreariness of victorian - era london and helped make the flashy killing scenes remind me of the crazy flashbacks in twin peaks , even though the violence in the film pales in comparison to that in the black - and - white comic . oscar winner martin childs ' ( shakespeare in love ) production design turns the original prague surroundings into one creepy place . even the acting in from hell is solid , with the dreamy depp turning in a typically strong performance and deftly handling a british accent . ians holm ( joe gould ' s secret ) and richardson ( 102 dalmatians ) log in great supporting roles , but the big surprise here is graham . i cringed the first time she opened her mouth , imagining her attempt at an irish accent , but it actually wasn ' t half bad . the film , however , is all good . 2 : 00 - r for strong violence / gore , sexuality , language and drug content\n"
     ]
    }
   ],
   "source": [
    "def get_review_text (clf,file_id,start=0,end=None):\n",
    "    words = list(mr.words(data[clf][file_id]))\n",
    "    return ' '.join(words[start:end])\n",
    "\n",
    "print(get_review_text('pos',0,end=95))\n",
    "\n",
    "print('     . . . . . . ')\n",
    "\n",
    "print(get_review_text('pos',0,start=-190))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading this makes it clear why movie reviews are hard, especially with the approach we're taking;  each word is treated as an independent feature whose presence increases or decreases the probability the review is positive. Overall it's positive review but it's not easy finding single words that might give us good evidence of that,\n",
    "and there are words that probably point the other way as well:\n",
    "\n",
    "```\n",
    "Pos         Neg\n",
    "-----------------\n",
    "ably      dreariness\n",
    "flashy    violence\n",
    "surprise  bad\n",
    "strong    creepy\n",
    "deftly    cringed\n",
    "good\n",
    "oscar\n",
    "winner\n",
    "great\n",
    "```\n",
    "\n",
    "Nevertheless, let's try this out and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: pos Actual: pos\n"
     ]
    }
   ],
   "source": [
    "predicted_label0 = classifier.classify(pos_test[0][0])\n",
    "\n",
    "print('Predicted: %s Actual: pos' % (predicted_label0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got it right!  Let's try a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: neg Actual: neg\n"
     ]
    }
   ],
   "source": [
    "predicted_label1 = classifier.classify(neg_test[0][0])\n",
    "\n",
    "print('Predicted: %s Actual: neg' % (predicted_label1,))\n",
    "\n",
    "# To see the the feature dictionary passed in to the classifier,\n",
    "# uncomment the next line\n",
    "#pos_test[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right again!\n",
    "\n",
    "Let's try the examples we cooked up before.  We need go to from\n",
    "a string like `\"Inception is the best movie ever\"` to a feature dictionary\n",
    "and pass that to the classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(unigram_features('Inception is the best movie ever'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(unigram_features(\"I could watch Inception many times\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting.  We may get some insight on this one below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most informative features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heres what our classifier learned.  These are the features for which the ratio of the positive to negative probability (or vice versa) is the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     15.6 : 1.0\n",
      "               ludicrous = True              neg : pos    =     14.2 : 1.0\n",
      "              astounding = True              pos : neg    =     12.3 : 1.0\n",
      "                  avoids = True              pos : neg    =     12.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =     11.8 : 1.0\n",
      "               atrocious = True              neg : pos    =     11.7 : 1.0\n",
      "             fascination = True              pos : neg    =     11.0 : 1.0\n",
      "                 offbeat = True              pos : neg    =     11.0 : 1.0\n",
      "               animators = True              pos : neg    =     10.3 : 1.0\n",
      "                  symbol = True              pos : neg    =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct response to the display above is to say, that's all very well but I need to\n",
    "see more.  Here's how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     15.6 : 1.0\n",
      "               ludicrous = True              neg : pos    =     14.2 : 1.0\n",
      "              astounding = True              pos : neg    =     12.3 : 1.0\n",
      "                  avoids = True              pos : neg    =     12.3 : 1.0\n",
      "                 idiotic = True              neg : pos    =     11.8 : 1.0\n",
      "               atrocious = True              neg : pos    =     11.7 : 1.0\n",
      "             fascination = True              pos : neg    =     11.0 : 1.0\n",
      "                 offbeat = True              pos : neg    =     11.0 : 1.0\n",
      "               animators = True              pos : neg    =     10.3 : 1.0\n",
      "                  symbol = True              pos : neg    =     10.3 : 1.0\n",
      "                religion = True              pos : neg    =     10.2 : 1.0\n",
      "                   jolie = True              neg : pos    =      9.7 : 1.0\n",
      "                  hudson = True              neg : pos    =      9.7 : 1.0\n",
      "                  annual = True              pos : neg    =      9.7 : 1.0\n",
      "               represent = True              pos : neg    =      9.7 : 1.0\n",
      "               insulting = True              neg : pos    =      9.4 : 1.0\n",
      "                seamless = True              pos : neg    =      9.0 : 1.0\n",
      "                    slip = True              pos : neg    =      9.0 : 1.0\n",
      "                   dread = True              pos : neg    =      9.0 : 1.0\n",
      "                   mulan = True              pos : neg    =      9.0 : 1.0\n",
      "               illogical = True              neg : pos    =      9.0 : 1.0\n",
      "                fairness = True              neg : pos    =      9.0 : 1.0\n",
      "                  hatred = True              pos : neg    =      9.0 : 1.0\n",
      "                   sucks = True              neg : pos    =      9.0 : 1.0\n",
      "               addresses = True              pos : neg    =      9.0 : 1.0\n",
      "              incoherent = True              neg : pos    =      9.0 : 1.0\n",
      "               stupidity = True              neg : pos    =      9.0 : 1.0\n",
      "                 chuckle = True              neg : pos    =      8.6 : 1.0\n",
      "                 winslet = True              pos : neg    =      8.3 : 1.0\n",
      "                 studies = True              pos : neg    =      8.3 : 1.0\n",
      "                 conveys = True              pos : neg    =      8.3 : 1.0\n",
      "                angelina = True              neg : pos    =      8.3 : 1.0\n",
      "                     dud = True              neg : pos    =      8.3 : 1.0\n",
      "                  feeble = True              neg : pos    =      8.3 : 1.0\n",
      "                 detract = True              pos : neg    =      8.3 : 1.0\n",
      "                    mpaa = True              pos : neg    =      8.3 : 1.0\n",
      "              accessible = True              pos : neg    =      8.3 : 1.0\n",
      "                 frances = True              pos : neg    =      8.3 : 1.0\n",
      "          excruciatingly = True              neg : pos    =      8.3 : 1.0\n",
      "                 wasting = True              neg : pos    =      8.3 : 1.0\n",
      "                    gump = True              pos : neg    =      8.3 : 1.0\n",
      "             uninvolving = True              neg : pos    =      7.8 : 1.0\n",
      "                    lore = True              pos : neg    =      7.7 : 1.0\n",
      "           unimaginative = True              neg : pos    =      7.7 : 1.0\n",
      "               furniture = True              neg : pos    =      7.7 : 1.0\n",
      "                narrates = True              pos : neg    =      7.7 : 1.0\n",
      "                    deft = True              pos : neg    =      7.7 : 1.0\n",
      "                embodies = True              pos : neg    =      7.7 : 1.0\n",
      "                gripping = True              pos : neg    =      7.4 : 1.0\n",
      "           unintentional = True              neg : pos    =      7.4 : 1.0\n",
      "                  forgot = True              neg : pos    =      7.3 : 1.0\n",
      "                  finest = True              pos : neg    =      7.2 : 1.0\n",
      "             wonderfully = True              pos : neg    =      7.1 : 1.0\n",
      "                    scum = True              pos : neg    =      7.0 : 1.0\n",
      "                  kenobi = True              pos : neg    =      7.0 : 1.0\n",
      "                 supreme = True              pos : neg    =      7.0 : 1.0\n",
      "                    sans = True              neg : pos    =      7.0 : 1.0\n",
      "                 amateur = True              neg : pos    =      7.0 : 1.0\n",
      "                reminder = True              pos : neg    =      7.0 : 1.0\n",
      "                 layered = True              pos : neg    =      7.0 : 1.0\n",
      "             overwrought = True              neg : pos    =      7.0 : 1.0\n",
      "                   pixar = True              pos : neg    =      7.0 : 1.0\n",
      "                  crappy = True              neg : pos    =      7.0 : 1.0\n",
      "                  filler = True              neg : pos    =      7.0 : 1.0\n",
      "                  denial = True              pos : neg    =      7.0 : 1.0\n",
      "                supports = True              pos : neg    =      7.0 : 1.0\n",
      "               behaviour = True              pos : neg    =      7.0 : 1.0\n",
      "                predator = True              neg : pos    =      7.0 : 1.0\n",
      "                 labeled = True              pos : neg    =      7.0 : 1.0\n",
      "                  shoddy = True              neg : pos    =      7.0 : 1.0\n",
      "                  seagal = True              neg : pos    =      7.0 : 1.0\n",
      "                   inept = True              neg : pos    =      6.8 : 1.0\n",
      "              schumacher = True              neg : pos    =      6.6 : 1.0\n",
      "               affecting = True              pos : neg    =      6.6 : 1.0\n",
      "               strongest = True              pos : neg    =      6.6 : 1.0\n",
      "                 depalma = True              neg : pos    =      6.3 : 1.0\n",
      "                   jumbo = True              neg : pos    =      6.3 : 1.0\n",
      "                   ditto = True              neg : pos    =      6.3 : 1.0\n",
      "              mediocrity = True              neg : pos    =      6.3 : 1.0\n",
      "                  fabric = True              pos : neg    =      6.3 : 1.0\n",
      "                    moss = True              pos : neg    =      6.3 : 1.0\n",
      "                   jules = True              pos : neg    =      6.3 : 1.0\n",
      "                   rabid = True              neg : pos    =      6.3 : 1.0\n",
      "               hawthorne = True              pos : neg    =      6.3 : 1.0\n",
      "               eszterhas = True              neg : pos    =      6.3 : 1.0\n",
      "               integrity = True              pos : neg    =      6.3 : 1.0\n",
      "                 cunning = True              pos : neg    =      6.3 : 1.0\n",
      "            refreshingly = True              pos : neg    =      6.3 : 1.0\n",
      "              weaknesses = True              pos : neg    =      6.3 : 1.0\n",
      "             fulfillment = True              pos : neg    =      6.3 : 1.0\n",
      "                  sexist = True              neg : pos    =      6.3 : 1.0\n",
      "                     bio = True              neg : pos    =      6.3 : 1.0\n",
      "                    jude = True              pos : neg    =      6.3 : 1.0\n",
      "             silverstone = True              neg : pos    =      6.3 : 1.0\n",
      "                 inspire = True              neg : pos    =      6.3 : 1.0\n",
      "                  turkey = True              neg : pos    =      6.3 : 1.0\n",
      "             magnificent = True              pos : neg    =      6.3 : 1.0\n",
      "            breathtaking = True              pos : neg    =      6.3 : 1.0\n",
      "                 insipid = True              neg : pos    =      6.2 : 1.0\n",
      "              unbearable = True              neg : pos    =      6.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have more features showing up as good indicators of positive, and this is a fairly good indicate or a probl;em with our classifier, as we'll see below.  Actually the classifier is a little too reluctant to classify reviews as negative on the test set.  This suggests that reliable negative indicators are not that common, at least on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serious evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell takes the first step toward testing a classifier a little more seriously.  It defines some code for evaluating classifier output.  The evaluation metrics defined are precision, recall, and accuracy.  Let N be the size of the dataset, $tp$ and $fp$ be true and false positive respectively and $tn$ and $fn$ be true and false negatives respective.  Accuracy is the percentage of correct answers out of the total corpus $\\left(\\frac{tp+tn}{N}\\right)$, Precision is the percentage of true positives out all positive guesses the system made $\\left(\\frac{tp}{tp + fp}\\right)$,\n",
    "while recall is the percentage of true positives out of all good reviews $\\left(\\frac{tp}{tp + fn}\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,accuracy_score\n",
    "\n",
    "def do_evaluation (pairs, pos_label='pos', verbose=True):\n",
    "    predicted, actual = list(zip(*pairs))\n",
    "    (precision, recall,accuracy) = (precision_score(actual,predicted,pos_label=pos_label), \n",
    "                                    recall_score(actual,predicted,pos_label=pos_label),\n",
    "                                    accuracy_score(actual,predicted))\n",
    "    if verbose:\n",
    "        print_results(precision, recall, accuracy, pos_label)\n",
    "    return (precision, recall,accuracy)\n",
    "\n",
    "def print_results (precision, recall, accuracy, pos_label):\n",
    "    banner =  'Evaluation with class label = %s' % pos_label\n",
    "    print()\n",
    "    print(banner)\n",
    "    print('=' * len(banner))\n",
    "    print('{0:10s} {1:.1f}'.format('Precision',precision*100))\n",
    "    print('{0:10s} {1:.1f}'.format('Recall',recall*100))\n",
    "    print('{0:10s} {1:.1f}'.format('Accuracy',accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell actually tests our NB classifier on the entire test set and prints out the result.  Note that precision and recall give different results depending on which  class we think of ourselves as detecting (which class we think of as positive).  We give evaluation numbers with respect to positive and negative reviews.  These show that our classifier actually misses a number of  negative reviews because it misclassifies them as positive (recall of positive high, recall of negative low).  Thus its high recall number when `pos_cls = pos` needs to be taken with a grain of salt.  It achieves this high recall by guessing positive a lot of the time.\n",
    "In fact, it guesses positive 74% of the time, even though it was trained on data that was 50% positive and 50% negative.\n",
    "\n",
    "This fact make it even more interesting that we correctly classified\n",
    "\n",
    "```\n",
    "I don't know how anyone could sit through Inception.\n",
    "```\n",
    "\n",
    "as negative.  In fact it turns out 'sit' is just a pretty good indicator of a negative review. It occurs 79 times in our set of 1000 negative reviews, quite often followed by 'through'.  This tells us something important.  Our intuitions aren't always good at finding good features.\n",
    "\n",
    "So why does our classifier guess positive so often?  Well, probably because it had more success finding strong positive indicators than it did finding strong negative indicators, as our glance at the most informative features suggested.  This is something we might want to worry about as we design good classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation with class label = pos\n",
      "=================================\n",
      "Precision  65.5\n",
      "Recall     97.0\n",
      "Accuracy   73.0\n",
      "\n",
      "Evaluation with class label = neg\n",
      "=================================\n",
      "Precision  94.2\n",
      "Recall     49.0\n",
      "Accuracy   73.0\n",
      "Note that 74.0% of our classifier guesses were positive\n",
      "While 50.0% of the reviews were actually positive\n"
     ]
    }
   ],
   "source": [
    "pairs = [(classifier.classify(example), actual)\n",
    "            for (example, actual) in test_set]\n",
    "\n",
    "do_evaluation (pairs)\n",
    "pos_guesses = [p for (p,a) in pairs if p=='pos']\n",
    "pos_actual = [a for (p,a) in pairs if a=='pos']\n",
    "do_evaluation (pairs, pos_label='neg')\n",
    "print('Note that {:.1%} of our classifier guesses were positive'.format(float(len(pos_guesses))/len(pairs)))\n",
    "print('While {:.1%} of the reviews were actually positive'.format(float(len(pos_actual))/len(pairs)))\n",
    "# to see the actual pairs that came out of the test uncomment the next line\n",
    "#pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will generate three experimental systems, each differing from the baseline system in the feature set\n",
    "that is used for classification.  At least one system must make use of information about feature value that you obtained by looking at `most_informative_features`. For each system:\n",
    "\n",
    "1. You will replace/modify `unigram_features` or replace/modify `extract_features` and hand in hard copies of your modified code.  If your code uses a list of words or any external data, you must include that data.  Note that this is Python code and it must be turned in in readable form. Python code whose indentation and formatting has been destroyed by placing it in a Word file will not be accepted. \n",
    "2. You will include hard copy showing the results of running your modified classifier on the test set.  It should look like the printout above, showing the results of precision and recall for both positive and negative labeling.\n",
    "\n",
    "Finally you will hand in a brief discussion comparing your three experiments and what worked and what didn't.  In discussing which classifier is better/worse you must make reference to the evaluation\n",
    "numbers, precision/recall for the positive and negative classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra credit:  Use information obtained from word similarity measures together with\n",
    "most informative features in one system.  The way to approach this is to take high value features and let highly similar words stand in place of actually seeing the word.  So if \"outstanding\" is a basic feature, but you've never seen \"excellent\" in the training data, let \"excellent\" count as making the \"outstanding\" feature be `True` (even though you never saw it in the training data) because `excellent` has a high similarity score to `outstanding`. See the optional [Word similarity assignment.](http://gawron.sdsu.edu/compling/course_core/assignments/word2Vec_assignment.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "243px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
